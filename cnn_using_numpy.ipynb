{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def affine_forward(x,w,b):\n",
    "    #forward pass affine layer\n",
    "    x_reshape = x.reshape(x.shape[0],-1)\n",
    "    out = np.dot(x_reshape,w) + b\n",
    "    cache = (x,w,b)\n",
    "    return out,cache\n",
    "\n",
    "def affine_backward(dout,cache):\n",
    "    x,w,b = cache\n",
    "    dx = np.dot(dout,w.T)\n",
    "    dw = np.dot(x.T,dout)\n",
    "    db = np.sum(dout,axis=0)\n",
    "    return dx,dw,db\n",
    "\n",
    "def relu_forward(x):\n",
    "    out = np.maximum(0,x)\n",
    "    cache = x\n",
    "    return out,cache\n",
    "\n",
    "def relu_backward(dout,cache):\n",
    "    x = cache\n",
    "    dx = dout\n",
    "    dx[x<=0] = 0\n",
    "    return dx\n",
    "\n",
    "def conv_forward(x,w,b,stride,pad):\n",
    "    # input x of shape (NxHxW)\n",
    "    # filter w of shape (FxHHxWW)\n",
    "    # bias b of shape (F,)\n",
    "    # conv_param is dictionary with keys stride and pad\n",
    "    \n",
    "    N,H,W = x.shape\n",
    "    F,HH,WW = w.shape\n",
    "    \n",
    "    H1 = ((H + 2*pad - HH) // stride) + 1\n",
    "    W1 = ((W + 2*pad - WW) // stride) + 1\n",
    "    \n",
    "    out = np.zeros((N,F,H1,W1))\n",
    "    pad_input = ((0,0),(pad,pad),(pad,pad))\n",
    "    x = np.pad(x,pad_width=pad_input,mode='constant',constant_values=0)\n",
    "    for i in range(N):\n",
    "        for j in range(F):\n",
    "            for k in range(H1):\n",
    "                p = k*stride\n",
    "                for l in range(W1):\n",
    "                    q = l*stride\n",
    "                    out[i,j,k,l] = np.sum(x[i,p:HH+p,q:WW+q] * w[j,:,:]) + b[j]\n",
    "    \n",
    "    cache = (x,w,b,stride,pad)\n",
    "    return out, cache\n",
    "\n",
    "def conv_backward(dout,cache):\n",
    "    #dout is upstream gradient\n",
    "    x,w,b,stride,pad = cache\n",
    "    dx = np.zeros_like(x)\n",
    "    dw = np.zeros_like(w)\n",
    "    db = np.zeros_like(b)\n",
    "    \n",
    "    N,H,W = x.shape\n",
    "    F,HH,WW = w.shape\n",
    "    H1 = ((H - HH) // stride) + 1\n",
    "    W1 = ((W - WW) // stride) + 1\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(F):\n",
    "            for k in range(H1):\n",
    "                p = k*stride\n",
    "                for l in range(W1):\n",
    "                    q = l*stride\n",
    "                    dx[i,p:HH+p,q:WW+q] += w[j,:,:]*dout[i,j,k,l]\n",
    "                    dw[j,:,:] += x[i,p:HH+p,q:WW+q]*dout[i,j,k,l]\n",
    "                    db[j] += dout[i,j,k,l]\n",
    "    dx = dx[:,pad:H-pad,pad:W-pad] \n",
    "    return dx,dw,db\n",
    "\n",
    "                \n",
    "def softmax_loss(x,y):\n",
    "    shifted_logits = x - np.max(x, axis=1, keepdims=True)\n",
    "    Z = np.sum(np.exp(shifted_logits), axis=1, keepdims=True)\n",
    "    log_probs = shifted_logits - np.log(Z)\n",
    "    probs = np.exp(log_probs)\n",
    "    N = x.shape[0]\n",
    "    loss = -np.sum(log_probs[np.arange(N), y]) / N\n",
    "    dx = probs.copy()\n",
    "    dx[np.arange(N), y] -= 1\n",
    "    dx /= N\n",
    "    return loss, dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs and parameters\n",
    "\n",
    "X = np.random.randn(1,32*32)\n",
    "#one input of size (32x32)\n",
    "X_reshape = X.reshape(1,32,32)\n",
    "#target vector of size (10,)\n",
    "y = np.random.randint(10, size=1)\n",
    "# 4 filters of size (3x3)\n",
    "Wconv1 = np.random.randn(4,3,3)\n",
    "bconv1 = np.zeros((4))\n",
    "W1 = np.random.randn(1024,10)\n",
    "b1 = np.zeros((10))\n",
    "stride = 2\n",
    "pad = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "#forward pass\n",
    "\n",
    "#convolution layer\n",
    "conv1,cache_conv = conv_forward(X_reshape,Wconv1,bconv1,stride,pad)\n",
    "\n",
    "#relu layer\n",
    "relu1,cache_relu = relu_forward(conv1)\n",
    "\n",
    "\n",
    "#affine_forward\n",
    "relu1_reshape = relu1.reshape(relu1.shape[0],-1)\n",
    "scores,cache_affine = affine_forward(relu1_reshape,W1,b1)\n",
    "print(scores.shape)\n",
    "\n",
    "#softmax loss\n",
    "loss, dscores = softmax_loss(scores,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024)\n"
     ]
    }
   ],
   "source": [
    "#backward pass\n",
    "\n",
    "# affine layer backward pass\n",
    "drelu1_reshape,dW1,db1 = affine_backward(dscores,cache_affine)\n",
    "\n",
    "# relu backward pass\n",
    "dout = drelu1_reshape.reshape(1,4,16,16)\n",
    "dconv1 = relu_backward(drelu1,cache_relu)\n",
    "\n",
    "# convolutional layer backward pass\n",
    "dX_reshape,dWconv1,dbconv1 = conv_backward(dconv1,cache_conv)\n",
    "dX = dX_reshape.reshape(dX_reshape.shape[0],-1)\n",
    "\n",
    "print(dX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
